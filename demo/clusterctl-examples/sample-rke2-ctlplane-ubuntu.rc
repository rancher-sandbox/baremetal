#
# Pod and service CIDR for the cluster
#
export POD_CIDR=192.168.0.0/18
export SERVICE_CIDR=10.96.0.0/12

#
# Cluster API host and port for *workload cluster* to be provisioned.
# This is *not* the host/IP and port of the management cluster.
# This is typically the virtual IP for an HA workload cluster.
#
# NOTE: make sure to pick an host/IP that is *unique* for each
# cluster and make sure the host/IP is outside the ranges
# of any IP pool.
#
export CLUSTER_APIENDPOINT_HOST=192.168.75.98
export CLUSTER_APIENDPOINT_PORT=6443

#
# IP range for the provisioning IP pool.
# This should be the (internal) provisioning network subnet.
#
export PROVISIONING_POOL_START=192.168.75.100
export PROVISIONING_POOL_END=192.168.75.200
# this is the CIDR prefix
export PROVISIONING_POOL_PREFIX=24

#
# IP range for the baremetal IP pool.
# This is can be either the management or public subnet.
#
export BAREMETAL_POOL_GATEWAY=10.84.81.14
export BAREMETAL_POOL_START=10.84.81.9
export BAREMETAL_POOL_END=10.84.81.11
# this is the CIDR prefix
export BAREMETEAL_POOL_PREFIX=24

#
# Base image used to provision the workload cluster.
# NOTE: the IMAGE_CHECKSUM can either be the checksum value or the URL
# to the checksum value.
#
export IMAGE_URL=http://media.suse.baremetal/ubuntu_22.04-efi.qcow2
export IMAGE_CHECKSUM=http://media.suse.baremetal/ubuntu_22.04-efi.qcow2.md5
export IMAGE_CHECKSUM_TYPE=md5
export IMAGE_FORMAT=qcow2


#####################################
# RKE2 Control Plane configurations #
#####################################

#
# Network configuration. The NIC names must match the ones that were
# discovered during baremetal host inspection. To see the NIC names
# of a given baremetal host. Run "kubectl get bmh <baremetal host> -o yaml".
# The name of the IP pool are coming from the clusterctl template.
#
# NOTE: these are YAML snippets to be injected into kubeadmConfigSpec so
# make sure we keep the 4 spaces indentation for each line.
#
export CONTROL_PLANE_NETWORK_DATA="
    links:
      ethernets:
      - id: ens1f0
        macAddress:
          fromHostInterface: ens1f0
        type: phy
      vlans:
      - id: ens1f0.1076
        vlanID: 1076
        vlanLink: ens1f0
        macAddress:
          string: ec:fd:aa:0d:22:5f
    networks:
      ipv4:
      - id: ens1f0
        ipAddressFromIPPool: provisioning-pool
        link: ens1f0
        routes:
        - gateway:
            string: 192.168.75.254
          network: 192.168.10.0
          prefix: 21
      - id: ens1f0.1076
        link: ens1f0.1076
        ipAddressFromIPPool: baremetalv4-pool
        routes:
        - gateway:
            fromIPPool: baremetalv4-pool
          network: 0.0.0.0
    services:
      dns:
      - 192.168.75.7
"

#
# Commands deploy RKE2 right after the base OS is successfully provisioned.
#
# NOTE: these are YAML snippets to be injected into kubeadmConfigSpec so
# make sure we keep the 6 spaces indentation for each line.
#
export RKE2_CONTROL_PLANE_DEPLOY_RKE2_COMMANDS="
      - echo 'net.ipv6.conf.all.disable_ipv6=1' >> /etc/sysctl.conf
      - echo 'net.ipv6.conf.default.disable_ipv6=1' >> /etc/sysctl.conf
      - echo 'net.ipv6.conf.lo.disable_ipv6=1' >> /etc/sysctl.conf
      - sysctl -p
      - apt update -y
      - apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common keepalived -y
      - if (curl -sk --max-time 10 https://192.168.75.98:6443/healthz); then echo 'keepalived already running';else systemctl start keepalived; fi
      - systemctl enable --now /lib/systemd/system/monitor.keepalived.service
      - curl -sfL https://get.rke2.io | sh -
      - systemctl enable rke2-server.service
      - systemctl start rke2-server.service
"

#########################
# Workers configuration #
#########################

#
# Network configuration. The NIC names must match the ones that were
# discovered during baremetal host inspection. To see the NIC names
# of a given baremetal host. Run "kubectl get bmh <baremetal host> -o yaml".
# The name of the IP pool are coming from the clusterctl template.
#
# NOTE: these are YAML snippets to be injected into kubeadmConfigSpec so
# make sure we keep the 4 spaces indentation for each line.
#
export WORKERS_NETWORK_DATA="
    links:
      ethernets:
      - id: eno49
        macAddress:
          fromHostInterface: eno49
        type: phy
      vlans:
      - id: eno49.1076
        vlanID: 1076
        vlanLink: eno49
        macAddress:
          string: 0e:32:f8:62:16:1c
    networks:
      ipv4:
      - id: eno49
        ipAddressFromIPPool: provisioning-pool
        link: eno49
        routes:
        - gateway:
            string: 192.168.75.254
          network: 192.168.10.0
          prefix: 21
      - id: eno49.1076
        link: eno49.1076
        ipAddressFromIPPool: baremetalv4-pool
        routes:
        - gateway:
            fromIPPool: baremetalv4-pool
          network: 0.0.0.0
    services:
      dns:
      - 192.168.75.7
"

#
# Commands to deploy RKE2 agent right after the base OS is provisioned.
#
# NOTE: these are YAML snippets to be injected into kubeadmConfigSpec so
# make sure we keep the 8 spaces indentation for each line.
#
export RKE2_WORKERS_DEPLOY_RKE2_COMMANDS="
        - echo 'net.ipv6.conf.all.disable_ipv6=1' >> /etc/sysctl.conf
        - echo 'net.ipv6.conf.default.disable_ipv6=1' >> /etc/sysctl.conf
        - echo 'net.ipv6.conf.lo.disable_ipv6=1' >> /etc/sysctl.conf
        - sysctl -p
        - apt update -y
        - apt install apt-transport-https ca-certificates curl gnupg-agent software-properties-common -y
        - curl -sfL https://get.rke2.io | INSTALL_RKE2_TYPE=agent sh -
        - systemctl enable rke2-agent.service
        - systemctl start rke2-agent.service
"
